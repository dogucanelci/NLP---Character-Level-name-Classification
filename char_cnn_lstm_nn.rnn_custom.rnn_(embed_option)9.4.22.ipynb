{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Doğu Can ELÇİ, MS Student at Istanbul Technical University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h style= \"color:red;font-size:50px\">NLP FROM SCRATCH: CLASSIFYING NAMES WITH A CHARACTER-LEVEL RNN,Custom-RNN,CNN and Bi-LSTM</h>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<l style=\"font-size:30 px;\">In this project, approximately 20 thousand tagged names from 18 languages were trained on a character basis using 8 different models, different batch-sizes and embedding-layers, and the results were shown.</l><br>\n",
    "<br><l style=\"font-size:30px;font-weight:bold\">Used models:</l><br><br>\n",
    "<strong>1- Include Embedding Layer:</strong><br>\n",
    "\n",
    "•&nbsp;CNN | batch-sizes: [128,64,32,16,8]<br>\n",
    "•&nbsp;bi-LSTM | batch-sizes: [128,64,32,16,8]<br>\n",
    "•&nbsp;nn.RNN | batch-sizes: [128,64,32,16,8]<br>\n",
    "•&nbsp;Customized-RNN | batch-sizes: [128]<br>\n",
    "<br>\n",
    "<strong>2- Without Embedding Layer:</strong><br><br>\n",
    "•&nbsp; CNN | batch-sizes: [128,64,32,16,8]<br>\n",
    "•&nbsp;bi-LSTM | batch-sizes: [128,64,32,16,8]<br>\n",
    "•&nbsp;nn.RNN | batch-sizes: [128,64,32,16,8]<br>\n",
    "•&nbsp;Customized-RNN | batch-sizes: [128]<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/names\\\\Arabic.txt', 'data/names\\\\Chinese.txt', 'data/names\\\\Czech.txt', 'data/names\\\\Dutch.txt', 'data/names\\\\English.txt', 'data/names\\\\French.txt', 'data/names\\\\German.txt', 'data/names\\\\Greek.txt', 'data/names\\\\Irish.txt', 'data/names\\\\Italian.txt', 'data/names\\\\Japanese.txt', 'data/names\\\\Korean.txt', 'data/names\\\\Polish.txt', 'data/names\\\\Portuguese.txt', 'data/names\\\\Russian.txt', 'data/names\\\\Scottish.txt', 'data/names\\\\Spanish.txt', 'data/names\\\\Vietnamese.txt']\n",
      "Slusarski\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "print(findFiles('data/names/*.txt'))\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'-\" #All upper and lower characters and some punctiations are added in all_letters.\n",
    "                                              #Last character(-) will use as a padding char.\n",
    "n_letters = len(all_letters)    #number of total letters\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s): # It converts some stranger characters to most similar latin letters.\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicodeToAscii('Ślusàrski'))  #For example in this name: Ś --> S\n",
    "\n",
    "# Build the category_lines dictionary, a list of names per language\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "for filename in findFiles('data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories) #number of languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns an index number as location of any letter in all_letters | Example: letter2index('a') -> 0\n",
    "def letter2index(letter):\n",
    "    letter = unicodeToAscii(letter)\n",
    "    return all_letters.find(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns an one-hot encoding tensor letter index is 1 and others are 0.(tensor size: 1,n_letters)\n",
    "def letter2tensor(letter):\n",
    "    idx = letter2index(letter)\n",
    "    torch_vec = torch.zeros(n_letters)\n",
    "    torch_vec[idx] = 1\n",
    "    return torch_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a tensor which include one-hot-encoded letter tensors inside.(tensor size: 1,name_length,n_letters)\n",
    "def name2tensor(name):\n",
    "    name_letter_tensor = torch.zeros(1,len(name),n_letters)\n",
    "    for idx,letter in enumerate(name):\n",
    "        name_letter_tensor[0][idx][letter2index(letter)] = 1\n",
    "    return name_letter_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 58])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name2tensor('Ali').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign a number to each language category\n",
    "def category_encoder(categories):\n",
    "    category_dict = {x:idx for idx,x in enumerate(categories)}\n",
    "    return category_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arabic': 0,\n",
       " 'Chinese': 1,\n",
       " 'Czech': 2,\n",
       " 'Dutch': 3,\n",
       " 'English': 4,\n",
       " 'French': 5,\n",
       " 'German': 6,\n",
       " 'Greek': 7,\n",
       " 'Irish': 8,\n",
       " 'Italian': 9,\n",
       " 'Japanese': 10,\n",
       " 'Korean': 11,\n",
       " 'Polish': 12,\n",
       " 'Portuguese': 13,\n",
       " 'Russian': 14,\n",
       " 'Scottish': 15,\n",
       " 'Spanish': 16,\n",
       " 'Vietnamese': 17}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_dict = category_encoder(category_lines.keys())\n",
    "category_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return total counts of each language category\n",
    "def get_category_counts(category_dict):\n",
    "    category_count_dict = {category:len(category_lines[category]) for category in category_dict.keys()}\n",
    "    return category_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arabic': 2000,\n",
       " 'Chinese': 268,\n",
       " 'Czech': 519,\n",
       " 'Dutch': 297,\n",
       " 'English': 3668,\n",
       " 'French': 277,\n",
       " 'German': 724,\n",
       " 'Greek': 203,\n",
       " 'Irish': 232,\n",
       " 'Italian': 709,\n",
       " 'Japanese': 991,\n",
       " 'Korean': 94,\n",
       " 'Polish': 139,\n",
       " 'Portuguese': 74,\n",
       " 'Russian': 9384,\n",
       " 'Scottish': 100,\n",
       " 'Spanish': 298,\n",
       " 'Vietnamese': 73}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total counts of languages\n",
    "category_counts_dict = get_category_counts(category_dict)\n",
    "category_counts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort total counts for each category and assign a dict\n",
    "category_counts_sorted = dict(sorted(category_counts_dict.items(), key=lambda x: x[1],reverse=True)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<l style= font-size:20px>As we can see below, Russian,English and Arabic are more than others as number.</l>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 18 artists>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1584x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.figure(figsize=(22,5))\n",
    "plt.bar(category_counts_sorted.keys(),category_counts_sorted.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<l style= \"font-size:20px\">Longest name has 20 char inside.</l>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the longest name in all names from all categories\n",
    "flatten_name_list = sum([name for name in category_lines.values()],[])\n",
    "max_name_size = sorted([len(name) for name in flatten_name_list])[-1]\n",
    "max_name_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Dataset Creating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20050"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_name_size = sum(category_counts_sorted.values()) # total name number: 20050\n",
    "X_tensor = [] #Include all one-hot-encoded name tensors \n",
    "y_tensor = [] #Include all name category numb tensors (target)\n",
    "for category in category_lines.keys():\n",
    "    for idx,name in enumerate(category_lines[category]): #This loop is used for make names a fixed size for fixed hidden layer sizes in nn.\n",
    "        name = name + '-'*(20 - len(name)) # padding char is selected as '-'.\n",
    "        X_tensor.append(name2tensor(name))\n",
    "        y_tensor.append(torch.tensor(category_dict[category]).view(1,))\n",
    "len(X_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20050, 20, 58])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor_reshaped = torch.concat(X_tensor, dim=0) #list to tensor\n",
    "X_tensor_reshaped.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20050])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tensor_reshaped = torch.concat(y_tensor,dim=0) #list to tensor\n",
    "y_tensor_reshaped.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature and target tensors are splited as train and test set as rate %10.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test , y_train ,y_test = train_test_split(X_tensor_reshaped.numpy(),y_tensor_reshaped.numpy(),test_size=0.1,random_state=42,stratify=y_tensor_reshaped.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18045, 20, 58), (2005, 20, 58), (18045,), (2005,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape , X_test.shape , y_train.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and test samples are splited as batch_size for preparing to training and testing.\n",
    "def train_test_loader(X_train,y_train,X_test,y_test,batch_size):\n",
    "    train_data = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
    "    train_loader = DataLoader(train_data, shuffle=False, batch_size=batch_size,drop_last=True)\n",
    "\n",
    "    valid_data = TensorDataset(torch.tensor(X_test), torch.tensor(y_test))\n",
    "    valid_loader = DataLoader(valid_data, shuffle=False, batch_size=batch_size,drop_last=True)\n",
    "    return train_loader,valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is global variable for embedding layer size for all models.\n",
    "EMBED_SIZE = 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4- Model Creating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, num_layers):\n",
    "    super(LSTMModel, self).__init__()\n",
    "    self.num_layers = num_layers\n",
    "    self.hidden_size = hidden_size\n",
    "    self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, batch_first = True, bidirectional = True)\n",
    "    self.in2output = nn.Linear(hidden_size + hidden_size, n_categories)\n",
    "\n",
    "  def forward(self, x, hidden_state):\n",
    "    #print(\"x: \", x.shape)  # x: torch.Size([128, 20, 58]) | (batch_size, seq_len, features)\n",
    "    #hidden_state[0].size() -> hidden_h0: torch.Size([2, 128, 128])\n",
    "    #hidden_state[1].size() -> hidden_c0: torch.Size([2, 128, 128])\n",
    "    # 128 + 128 because it is bi-directional model !\n",
    "    # c0(cell state) + h0(hidden state) --> 128 (combined by nn.LSTM just like nn.RNN)\n",
    "    output, hidden_state = self.lstm(x, hidden_state) #output.size() -> torch.Size([128, 20, 256])(128 short + 128 long)\n",
    "                                                      #hidden_state[0].size() -> hidden_h0: torch.Size([2, 128, 128])\n",
    "                                                      #hidden_state[1].size() -> hidden_c0: torch.Size([2, 128, 128])\n",
    "    output = self.in2output(output[:, -1, :]) #last char embed of name include all information of previous ones.\n",
    "                                              #output.size() -> 128,256(128 short + 128 long)\n",
    "    return output\n",
    "\n",
    "  def init_hidden(self, batch_size):\n",
    "    # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "    # initialized to zero, for hidden state and cell state of LSTM\n",
    "    h0 = torch.zeros(self.num_layers*2,batch_size,self.hidden_size)\n",
    "    c0 = torch.zeros(self.num_layers*2,batch_size,self.hidden_size)\n",
    "    hidden = (h0,c0)\n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel_Embed(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, num_layers):\n",
    "    super(LSTMModel_Embed, self).__init__()\n",
    "    self.num_layers = num_layers\n",
    "    self.hidden_size = hidden_size\n",
    "    self.embed = nn.Embedding(input_size, EMBED_SIZE)\n",
    "    self.lstm = nn.LSTM(input_size = EMBED_SIZE, hidden_size = hidden_size, num_layers = num_layers, batch_first = True, bidirectional = True)\n",
    "    self.in2output = nn.Linear(hidden_size + hidden_size, n_categories)\n",
    "\n",
    "  def forward(self, x, hidden_state):\n",
    "\n",
    "    argmax_x = torch.argmax(x,dim=2)\n",
    "    embed = self.embed(argmax_x)\n",
    "    output, hidden_state = self.lstm(embed, hidden_state)\n",
    "\n",
    "    output = self.in2output(output[:, -1, :]) #last char embed of name include all information of previous ones.\n",
    "    return output\n",
    "\n",
    "  def init_hidden(self, batch_size):\n",
    "    # Initialization two new tensors which are cell and hidden state.\n",
    "    h0 = torch.zeros(self.num_layers*2,batch_size,self.hidden_size)\n",
    "    c0 = torch.zeros(self.num_layers*2,batch_size,self.hidden_size)\n",
    "    hidden = (h0,c0)\n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, num_layers):\n",
    "    super(RNNModel, self).__init__()\n",
    "    self.num_layers = num_layers\n",
    "    self.hidden_size = hidden_size\n",
    "    self.rnn1 = nn.RNN(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, batch_first = True)\n",
    "    self.in2output = nn.Linear(hidden_size, n_categories)\n",
    "\n",
    "  def forward(self, x, hidden_state):\n",
    "    # 128 + 128 her türlü 256 olmak zorunda !!! *** \n",
    "    output, hidden_state = self.rnn1(x, hidden_state) # nn.RNN module combines 58 and 128 somehow and output size is also 128.\n",
    "    output = self.in2output(output[:, -1, :]) #last char embed of name include all information of previous ones.\n",
    "    return output\n",
    "\n",
    "  def init_hidden(self, batch_size):\n",
    "    h0 = torch.zeros(self.num_layers,batch_size,self.hidden_size)\n",
    "    hidden = h0\n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel_Embed(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, num_layers):\n",
    "    super(RNNModel_Embed, self).__init__()\n",
    "    self.num_layers = num_layers\n",
    "    self.hidden_size = hidden_size\n",
    "    self.embed = nn.Embedding(input_size, EMBED_SIZE)\n",
    "    self.rnn1 = nn.RNN(input_size = EMBED_SIZE, hidden_size = hidden_size, num_layers = num_layers, batch_first = True)\n",
    "    self.in2output = nn.Linear(hidden_size, n_categories)\n",
    "\n",
    "  def forward(self, x, hidden_state):\n",
    "\n",
    "    # 128 + 128 her türlü 256 olmak zorunda !!! *** \n",
    "    x_argmax = torch.argmax(x,dim=2)   #one_hot to index vector | torch.Size([128, 20, 58]) --> torch.Size([128, 20])    \n",
    "    embed = self.embed(x_argmax)       #embedded.size() --> torch.Size([128, 20, 10])\n",
    "    output, hidden_state = self.rnn1(embed, hidden_state)\n",
    "\n",
    "    output = self.in2output(output[:, -1, :]) #last char embed of name include all information of previous ones.\n",
    "\n",
    "    return output\n",
    "\n",
    "  def init_hidden(self, batch_size):\n",
    "    # initialization of new hidden state tensor\n",
    "    h0 = torch.zeros(self.num_layers,batch_size,self.hidden_size)\n",
    "    hidden = h0\n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CustomRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(CustomRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, n_categories)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined1 = torch.cat((input,hidden.view(self.hidden_size)),0)\n",
    "\n",
    "        hidden = self.i2h(combined1)\n",
    "        output = self.i2o(combined1)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1,self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CustomRNN_Embed(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(CustomRNN_Embed, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        #self.vocab_size = vocab_size\n",
    "        self.embed = nn.Embedding(input_size, EMBED_SIZE) #one_hot to index vector | torch.Size([1, 58]) --> torch.Size([1, 20])\n",
    "        self.i2h = nn.Linear(EMBED_SIZE + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(EMBED_SIZE + hidden_size, n_categories)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        x_argmax = torch.argmax(input,dim=0)\n",
    "        embeds = self.embed(x_argmax)\n",
    "        combined1 = torch.cat((embeds,hidden.view(self.hidden_size)),0)\n",
    "\n",
    "        hidden = self.i2h(combined1)\n",
    "        output = self.i2o(combined1)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1,self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self,input_size, n_filters, filter_sizes):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(input_size,n_filters, kernel_size=filter_sizes, padding='same') #(58,20) --> (4,20) | padding: return same size\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2) #(4,20) --> (4,10)\n",
    "        self.fc1 = nn.Linear(n_filters*10, n_categories) #size of output linear layer has to assign manually before.\n",
    "                                                         # 40 -> 18\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1) #torch.Size([128, 20, 58]) --> torch.Size([128, 58, 20])\n",
    "        conved = F.relu(self.conv1(x)) #Mapping with Convolutional layer and activated with ReLu | conved.size()-->torch.Size([128, 4, 20])\n",
    "        pooled = self.pool(conved)  #decrease matrix size with selection of max cells | torch.Size([128, 4, 20]) --> torch.Size([128, 4, 10])\n",
    "        x = torch.flatten(pooled,1) # make array to 1d | x.size() --> torch.Size([128, 40])\n",
    "        x = F.relu(self.fc1(x)) #1d flatted-input activated with ReLu\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "class CNNModel_Embed(nn.Module):\n",
    "    def __init__(self,input_size, n_filters, filter_sizes):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(input_size, EMBED_SIZE) #(max_name_size,n_letters) --> (max_name_size,embedded_size)\n",
    "                                                          #(20,58) --> (20,10)\n",
    "        self.conv1 = nn.Conv1d(EMBED_SIZE,n_filters, kernel_size=filter_sizes, padding='same') #(58,20) --> (4,20) | padding: return same size\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2) #(4,20) --> (4,10)\n",
    "        self.fc1 = nn.Linear(n_filters*10, n_categories) #size of output linear layer has to assign manually before.\n",
    "                                                         # 40 -> 18\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_argmax = torch.argmax(x,dim=2)     #one_hot to index vector | torch.Size([128, 20, 58]) --> torch.Size([128, 20])\n",
    "        embedded = self.embed(x_argmax)      #embedded.size() --> torch.Size([128, 20, 10])\n",
    "        embedded = embedded.permute(0, 2, 1) #torch.Size([128, 20, 10]) --> torch.Size([128, 10, 20])\n",
    "        conved = F.relu(self.conv1(embedded)) #Mapping with Convolutional layer and activated with ReLu | conved.size()-->torch.Size([128, 4, 20])\n",
    "        pooled = self.pool(conved) #decrease matrix size with selection of max cells | torch.Size([128, 4, 20]) --> torch.Size([128, 4, 10])\n",
    "        x = torch.flatten(pooled,1) # make array to 1d | x.size() --> torch.Size([128, 40])\n",
    "        x = F.relu(self.fc1(x)) # 1d flatted-input activated with ReLu\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return loss function(CrossEntropyLoss), model(nn.CNN) with or without Embedding layer and optimizer function(Adam Optimizer) \n",
    "def create_cnn_model(is_embedding = False):\n",
    "    n_filters = 4 #number of filters\n",
    "    filter_size = 2 # 1d filter progress with 2 window-size (for this project,2 char)\n",
    "    learning_rate = 0.001 #step size of current update process of weights\n",
    "    epochs =  10 #number of updating process with all training samples\n",
    "    if is_embedding: #CNN model with Embedding layer\n",
    "        model = CNNModel_Embed(n_letters , n_filters, filter_size)\n",
    "    else:  #CNN model without Embedding layer\n",
    "        model = CNNModel(n_letters , n_filters, filter_size)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    # defining loss function\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    return model,optimizer,loss_func,epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return loss function(CrossEntropyLoss), model(nn.LSTM) with or without Embedding layer and optimizer function(Adam Optimizer)\n",
    "def create_lstm_model(is_embedding = False):\n",
    "    hidden_size = 128\n",
    "    learning_rate = 0.001\n",
    "    epochs = 10\n",
    "    if is_embedding:  #LSTM model with Embedding layer\n",
    "        model = LSTMModel_Embed(n_letters , hidden_size, 1)\n",
    "    else:  #LSTM model without Embedding layer\n",
    "        model = LSTMModel(n_letters , hidden_size, 1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    # defining loss function\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    #loss_fn = nn.NLLLoss()\n",
    "    return model,optimizer,loss_func,epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return loss function(CrossEntropyLoss), model(nn.RNN) with or without Embedding layer and optimizer function(Adam Optimizer)\n",
    "def create_rnn_model(is_embedding = False):\n",
    "    hidden_size = 128\n",
    "    learning_rate = 0.001\n",
    "    epochs = 10\n",
    "    if is_embedding:  #nn.RNN model with Embedding layer\n",
    "        model = RNNModel_Embed(n_letters , hidden_size, 1)\n",
    "    else:  #nn.RNN model with Embedding layer\n",
    "        model = RNNModel(n_letters , hidden_size, 1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    # defining loss function\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    #loss_fn = nn.NLLLoss()\n",
    "    return model,optimizer,loss_func,epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return loss function(CrossEntropyLoss), model(customized RNN) with or without Embedding layer and optimizer function(Adam Optimizer)\n",
    "def create_custom_rnn_model(is_embedding = False):\n",
    "    hidden_size = 128\n",
    "    learning_rate = 0.001\n",
    "    epochs = 10\n",
    "    if is_embedding:  #Customized RNN model with Embedding layer\n",
    "        model = CustomRNN_Embed(n_letters,hidden_size)\n",
    "    else:  #Customized RNN model with Embedding layer\n",
    "        model = CustomRNN(n_letters,hidden_size)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    # define loss function\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    return model,optimizer,loss_func,epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_2(pred,label): #Return how much true label match with predictions(max prob. class index)\n",
    "    return torch.sum(torch.argmax(pred,dim=1) == label).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5- Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_train_test_process(has_embedding=False):\n",
    "\n",
    "  batch_list = [128,64,16,8]\n",
    "  main_accuracy_dict = {} #accuracy dict (keys: batch_sizes, values: accuracy)\n",
    "  for batch_i in batch_list:\n",
    "    #model,optimizer_128,loss_func = create_model()\n",
    "    model,optimizer_128,loss_func,epochs = create_cnn_model(has_embedding)\n",
    "    batch_size = batch_i #current batch-size\n",
    "    train_loader,valid_loader = train_test_loader(X_train,y_train,X_test,y_test,batch_size) #preparing train and test datasets\n",
    "    best_accuracy = 0 #best accuracy of each batch_size\n",
    "\n",
    "    for i in range(epochs): #epoch-i\n",
    "      total_train_loss = 0\n",
    "      for batch in (train_loader): #batch[0].size = torch.Size([128, 20, 58]) , batch[1].size = torch.Size([128])\n",
    "        model.zero_grad()\n",
    "        # forward process according to batch-size\n",
    "        outputs1 = model(batch[0])\n",
    "        # computing training loss\n",
    "        loss = loss_func(outputs1, batch[1])\n",
    "        total_train_loss += loss.item()\n",
    "        # backward process according to batch-size\n",
    "        loss.backward()\n",
    "        # updating parameters\n",
    "        optimizer_128.step()\n",
    "\n",
    "      # calculating average train loss\n",
    "      avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "      val_accuracy = [] #validation accuracy list\n",
    "      val_loss = [] #validation loss list\n",
    "      for batch in valid_loader:\n",
    "        # gradients ignored for a while for testing (it speeds up computation)\n",
    "        with torch.no_grad():\n",
    "            pred = model(batch[0])\n",
    "        # computing loss\n",
    "        loss = loss_func(outputs1, batch[1])\n",
    "        val_loss.append(loss.item())\n",
    "  #Validation process\n",
    "        acc = accuracy_2(pred,batch[1])\n",
    "        val_accuracy.append(acc/batch_size)\n",
    "      val_mean_acc = np.mean(val_accuracy)\n",
    "      val_mean_loss = np.mean(val_loss)\n",
    "\n",
    "      if val_mean_acc > best_accuracy:\n",
    "          best_accuracy = val_mean_acc\n",
    "\n",
    "      # print performance\n",
    "      print(f'Epoch no: {i+1} | Train_loss: {round(avg_train_loss,5)} | Val_loss: {round(val_mean_loss,5)} | Val_Accuracy: {round(val_mean_acc,2)}')\n",
    "    print(f\"Best accuracy is : %{best_accuracy*100} for batch_size ={batch_size}\")\n",
    "    main_accuracy_dict[batch_size] = best_accuracy\n",
    "  return main_accuracy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_train_test_process(has_embedding=False):\n",
    "\n",
    "  batch_list = [128,64,16,8]\n",
    "  main_accuracy_dict = {}\n",
    "  for batch_i in batch_list:\n",
    "    model,optimizer_128,loss_func,epochs = create_lstm_model(has_embedding)\n",
    "    batch_size = batch_i\n",
    "    train_loader,valid_loader = train_test_loader(X_train,y_train,X_test,y_test,batch_size)\n",
    "    best_accuracy = 0 #best accuracy of each batch_size\n",
    "\n",
    "    for i in range(epochs):\n",
    "      total_train_loss = 0\n",
    "      for batch in train_loader: #batch[0].size = torch.Size([128, 20, 58]) , batch[1].size = torch.Size([128])\n",
    "        model.zero_grad()\n",
    "        # performing forward pass\n",
    "        init_hidden = model.init_hidden(batch_size)\n",
    "        #logits = model(b_input_ids,init_hidden)\n",
    "        outputs1 = model(batch[0],init_hidden)\n",
    "        # computing loss\n",
    "        loss = loss_func(outputs1, batch[1])\n",
    "        total_train_loss += loss.item()\n",
    "        # performing a backward pass\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optimizer_128.step()\n",
    "\n",
    "      # calculate the average loss\n",
    "      avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "\n",
    "      val_accuracy = []\n",
    "      val_loss = []\n",
    "      for batch in valid_loader:\n",
    "        # gradients ignored for a while for testing (it speeds up computation)\n",
    "        with torch.no_grad():\n",
    "            init_hidden = model.init_hidden(batch_size)\n",
    "            pred = model(batch[0],init_hidden)\n",
    "        # computing loss\n",
    "        loss = loss_func(outputs1, batch[1])\n",
    "        val_loss.append(loss.item())\n",
    "  #Validation process\n",
    "        acc = accuracy_2(pred,batch[1])\n",
    "        val_accuracy.append(acc/batch_size)\n",
    "      val_mean_acc = np.mean(val_accuracy)\n",
    "      val_mean_loss = np.mean(val_loss)\n",
    "\n",
    "      if val_mean_acc > best_accuracy:\n",
    "          best_accuracy = val_mean_acc\n",
    "\n",
    "      # print performance\n",
    "      print(f'Epoch no: {i+1} | Train_loss: {round(avg_train_loss,5)} | Val_loss: {round(val_mean_loss,5)} | Val_Accuracy: {round(val_mean_acc,2)}')\n",
    "    print(f\"Best accuracy is : %{best_accuracy*100} for batch_size ={batch_size}\")\n",
    "    main_accuracy_dict[batch_size] = best_accuracy\n",
    "  return main_accuracy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_train_test_process(has_embedding=False):\n",
    "  batch_list = [128,64,16,8]\n",
    "  main_accuracy_dict = {}\n",
    "  for batch_i in batch_list:\n",
    "    model,optimizer,loss_func,epochs = create_rnn_model(has_embedding)\n",
    "    batch_size = batch_i\n",
    "    train_loader,valid_loader = train_test_loader(X_train,y_train,X_test,y_test,batch_size)\n",
    "    best_accuracy = 0 #best accuracy of each batch_size\n",
    "\n",
    "    for i in range(epochs):\n",
    "      total_train_loss = 0\n",
    "      for batch in train_loader: #batch[0].size = torch.Size([128, 20, 58]) , batch[1].size = torch.Size([128])\n",
    "        model.zero_grad()\n",
    "        # performing forward pass\n",
    "        init_hidden = model.init_hidden(batch_size) # init_hidden.size() --> torch.Size([1, 64, 128]) (hidden_layer_num,batch_size,hidden_size)\n",
    "        #outputs1 = model(b_input_ids,init_hidden)\n",
    "        outputs1 = model(batch[0],init_hidden)\n",
    "        # computing loss\n",
    "        loss = loss_func(outputs1, batch[1])\n",
    "        total_train_loss += loss.item()\n",
    "        # performing a backward pass\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "      # calculate the average loss\n",
    "      avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "\n",
    "      val_accuracy = []\n",
    "      val_loss = []\n",
    "      for batch in valid_loader:\n",
    "        # gradients ignored for a while for testing (it speeds up computation)\n",
    "        with torch.no_grad():\n",
    "            init_hidden = model.init_hidden(batch_size)\n",
    "            pred = model(batch[0],init_hidden)\n",
    "        # computing loss\n",
    "        loss = loss_func(outputs1, batch[1])\n",
    "        val_loss.append(loss.item())\n",
    "  #Validation process\n",
    "        acc = accuracy_2(pred,batch[1])\n",
    "        val_accuracy.append(acc/batch_size)\n",
    "      val_mean_acc = np.mean(val_accuracy)\n",
    "      val_mean_loss = np.mean(val_loss)\n",
    "      if val_mean_acc > best_accuracy:\n",
    "          best_accuracy = val_mean_acc\n",
    "\n",
    "      # print performance\n",
    "      print(f'Epoch no: {i+1} | Train_loss: {round(avg_train_loss,5)} | Val_loss: {round(val_mean_loss,5)} | Val_Accuracy: {round(val_mean_acc,2)}')\n",
    "    print(f\"Best accuracy is : %{best_accuracy*100} for batch_size ={batch_size}\")\n",
    "    main_accuracy_dict[batch_size] = best_accuracy\n",
    "  return main_accuracy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_rnn_train_test_process(has_embedding=False):\n",
    "  batch_list = [128]\n",
    "  main_accuracy_dict = {}\n",
    "  for batch_i in batch_list:\n",
    "    batch_size = batch_i\n",
    "    model,optimizer_128,loss_func,epochs = create_custom_rnn_model(has_embedding)\n",
    "    train_loader,valid_loader = train_test_loader(X_train,y_train,X_test,y_test,batch_size)\n",
    "    best_accuracy = 0 #best accuracy of each batch_size\n",
    "\n",
    "    for i in range(epochs):\n",
    "      # tracking time and loss\n",
    "      total_train_loss = 0\n",
    "      for batch in train_loader: #batch[0].size = torch.Size([128, 20, 58]) , batch[1].size = torch.Size([128])\n",
    "        model.zero_grad() #reset gradients after each update\n",
    "        # performing forward pass\n",
    "        init_hidden = model.init_hidden()\n",
    "        hidden = init_hidden\n",
    "        outputs1_tensor = torch.zeros(batch_size,n_categories)\n",
    "        for idx,name in enumerate(batch[0]):\n",
    "          for char in name:\n",
    "            outputs1,hidden = model(char,hidden)\n",
    "          outputs1_tensor[idx] = outputs1\n",
    "        # computing loss\n",
    "        loss = loss_func(outputs1_tensor, batch[1])\n",
    "        total_train_loss += loss.item()\n",
    "        # performing a backward pass\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optimizer_128.step()\n",
    "\n",
    "      # calculate the average loss\n",
    "      avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "      val_accuracy = []\n",
    "      val_loss = []\n",
    "      for batch in valid_loader:\n",
    "        # gradients ignored for a while for testing (it speeds up computation)\n",
    "        with torch.no_grad():\n",
    "            init_hidden = model.init_hidden()\n",
    "            pred_tensor = torch.zeros(batch_size,n_categories)\n",
    "            for idx,name in enumerate(batch[0]):\n",
    "              for char in name:\n",
    "                outputs1,hidden = model(char,hidden)\n",
    "              pred_tensor[idx] = outputs1\n",
    "        # computing loss\n",
    "        loss = loss_func(pred_tensor, batch[1])\n",
    "        val_loss.append(loss.item())\n",
    "    #Validation process\n",
    "        acc = accuracy_2(pred_tensor,batch[1])\n",
    "        val_accuracy.append(acc/batch_size)\n",
    "      val_mean_acc = np.mean(val_accuracy)\n",
    "      val_mean_loss = np.mean(val_loss)\n",
    "      if val_mean_acc > best_accuracy:\n",
    "          best_accuracy = val_mean_acc\n",
    "\n",
    "      # print performance\n",
    "      print(f'Epoch no: {i+1} | Train_loss: {round(avg_train_loss,5)} | Val_loss: {round(val_mean_loss,5)} | Val_Accuracy: {round(val_mean_acc,2)}')\n",
    "    print(f\"Best accuracy is : %{best_accuracy*100} for batch_size ={batch_size}\")\n",
    "    main_accuracy_dict[batch_size] = best_accuracy\n",
    "  return main_accuracy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no: 1 | Train_loss: 1.9112 | Val_loss: 1.84974 | Val_Accuracy: 0.47\n",
      "Epoch no: 2 | Train_loss: 1.84737 | Val_loss: 1.84811 | Val_Accuracy: 0.47\n",
      "Epoch no: 3 | Train_loss: 1.59658 | Val_loss: 2.56808 | Val_Accuracy: 0.56\n",
      "Epoch no: 4 | Train_loss: 1.43379 | Val_loss: 2.70626 | Val_Accuracy: 0.6\n",
      "Epoch no: 5 | Train_loss: 1.32368 | Val_loss: 2.83209 | Val_Accuracy: 0.64\n",
      "Epoch no: 6 | Train_loss: 1.23472 | Val_loss: 3.02704 | Val_Accuracy: 0.65\n",
      "Epoch no: 7 | Train_loss: 1.16008 | Val_loss: 3.09695 | Val_Accuracy: 0.69\n",
      "Epoch no: 8 | Train_loss: 1.0473 | Val_loss: 3.40978 | Val_Accuracy: 0.72\n",
      "Epoch no: 9 | Train_loss: 0.94523 | Val_loss: 3.47285 | Val_Accuracy: 0.74\n",
      "Epoch no: 10 | Train_loss: 0.87628 | Val_loss: 3.66282 | Val_Accuracy: 0.75\n",
      "Best accuracy is : %74.63541666666667 for batch_size =128\n",
      "Epoch no: 1 | Train_loss: 1.88883 | Val_loss: 1.84457 | Val_Accuracy: 0.47\n",
      "Epoch no: 2 | Train_loss: 1.61447 | Val_loss: 2.3895 | Val_Accuracy: 0.58\n",
      "Epoch no: 3 | Train_loss: 1.39768 | Val_loss: 2.7665 | Val_Accuracy: 0.62\n",
      "Epoch no: 4 | Train_loss: 1.19827 | Val_loss: 3.196 | Val_Accuracy: 0.69\n",
      "Epoch no: 5 | Train_loss: 1.04283 | Val_loss: 3.4885 | Val_Accuracy: 0.72\n",
      "Epoch no: 6 | Train_loss: 0.93128 | Val_loss: 3.78441 | Val_Accuracy: 0.74\n",
      "Epoch no: 7 | Train_loss: 0.84217 | Val_loss: 4.07177 | Val_Accuracy: 0.76\n",
      "Epoch no: 8 | Train_loss: 0.77944 | Val_loss: 4.26 | Val_Accuracy: 0.77\n",
      "Epoch no: 9 | Train_loss: 0.72328 | Val_loss: 4.40028 | Val_Accuracy: 0.78\n",
      "Epoch no: 10 | Train_loss: 0.68507 | Val_loss: 4.61032 | Val_Accuracy: 0.78\n",
      "Best accuracy is : %78.32661290322581 for batch_size =64\n",
      "Epoch no: 1 | Train_loss: 1.86833 | Val_loss: 1.84795 | Val_Accuracy: 0.47\n",
      "Epoch no: 2 | Train_loss: 1.85282 | Val_loss: 1.84695 | Val_Accuracy: 0.47\n",
      "Epoch no: 3 | Train_loss: 1.85121 | Val_loss: 1.84639 | Val_Accuracy: 0.47\n",
      "Epoch no: 4 | Train_loss: 1.76885 | Val_loss: 2.46212 | Val_Accuracy: 0.57\n",
      "Epoch no: 5 | Train_loss: 1.29306 | Val_loss: 2.9771 | Val_Accuracy: 0.69\n",
      "Epoch no: 6 | Train_loss: 0.95786 | Val_loss: 3.31927 | Val_Accuracy: 0.74\n",
      "Epoch no: 7 | Train_loss: 0.80039 | Val_loss: 3.79171 | Val_Accuracy: 0.77\n",
      "Epoch no: 8 | Train_loss: 0.71263 | Val_loss: 4.00208 | Val_Accuracy: 0.78\n",
      "Epoch no: 9 | Train_loss: 0.64267 | Val_loss: 4.31636 | Val_Accuracy: 0.79\n",
      "Epoch no: 10 | Train_loss: 0.58846 | Val_loss: 4.70537 | Val_Accuracy: 0.79\n",
      "Best accuracy is : %79.3 for batch_size =16\n",
      "Epoch no: 1 | Train_loss: 1.8647 | Val_loss: 1.84703 | Val_Accuracy: 0.47\n",
      "Epoch no: 2 | Train_loss: 1.8535 | Val_loss: 1.84633 | Val_Accuracy: 0.47\n",
      "Epoch no: 3 | Train_loss: 1.85156 | Val_loss: 1.84579 | Val_Accuracy: 0.47\n",
      "Epoch no: 4 | Train_loss: 1.85037 | Val_loss: 1.84543 | Val_Accuracy: 0.47\n",
      "Epoch no: 5 | Train_loss: 1.84954 | Val_loss: 1.84512 | Val_Accuracy: 0.47\n",
      "Epoch no: 6 | Train_loss: 1.83061 | Val_loss: 2.14776 | Val_Accuracy: 0.54\n",
      "Epoch no: 7 | Train_loss: 1.43293 | Val_loss: 2.9253 | Val_Accuracy: 0.65\n",
      "Epoch no: 8 | Train_loss: 1.23137 | Val_loss: 3.44887 | Val_Accuracy: 0.68\n",
      "Epoch no: 9 | Train_loss: 1.04843 | Val_loss: 3.71793 | Val_Accuracy: 0.73\n",
      "Epoch no: 10 | Train_loss: 0.81524 | Val_loss: 4.474 | Val_Accuracy: 0.78\n",
      "Best accuracy is : %77.55 for batch_size =8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{128: 0.7463541666666667, 64: 0.7832661290322581, 16: 0.793, 8: 0.7755}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_dict_embed = lstm_train_test_process(has_embedding=True)\n",
    "lstm_dict_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no: 1 | Train_loss: 1.94543 | Val_loss: 1.84957 | Val_Accuracy: 0.47\n",
      "Epoch no: 2 | Train_loss: 1.84775 | Val_loss: 1.8494 | Val_Accuracy: 0.47\n",
      "Epoch no: 3 | Train_loss: 1.84762 | Val_loss: 1.84905 | Val_Accuracy: 0.47\n",
      "Epoch no: 4 | Train_loss: 1.84747 | Val_loss: 1.84864 | Val_Accuracy: 0.47\n",
      "Epoch no: 5 | Train_loss: 1.8473 | Val_loss: 1.84822 | Val_Accuracy: 0.47\n",
      "Epoch no: 6 | Train_loss: 1.84705 | Val_loss: 1.84784 | Val_Accuracy: 0.47\n",
      "Epoch no: 7 | Train_loss: 1.75953 | Val_loss: 2.24334 | Val_Accuracy: 0.54\n",
      "Epoch no: 8 | Train_loss: 1.48136 | Val_loss: 2.5517 | Val_Accuracy: 0.56\n",
      "Epoch no: 9 | Train_loss: 1.37942 | Val_loss: 2.90325 | Val_Accuracy: 0.63\n",
      "Epoch no: 10 | Train_loss: 1.21376 | Val_loss: 3.12367 | Val_Accuracy: 0.66\n",
      "Best accuracy is : %66.35416666666667 for batch_size =128\n",
      "Epoch no: 1 | Train_loss: 1.90013 | Val_loss: 1.84475 | Val_Accuracy: 0.47\n",
      "Epoch no: 2 | Train_loss: 1.84884 | Val_loss: 1.84428 | Val_Accuracy: 0.47\n",
      "Epoch no: 3 | Train_loss: 1.84831 | Val_loss: 1.84398 | Val_Accuracy: 0.47\n",
      "Epoch no: 4 | Train_loss: 1.70803 | Val_loss: 2.36879 | Val_Accuracy: 0.55\n",
      "Epoch no: 5 | Train_loss: 1.40749 | Val_loss: 2.66968 | Val_Accuracy: 0.62\n",
      "Epoch no: 6 | Train_loss: 1.20907 | Val_loss: 2.98897 | Val_Accuracy: 0.67\n",
      "Epoch no: 7 | Train_loss: 1.12219 | Val_loss: 3.19964 | Val_Accuracy: 0.69\n",
      "Epoch no: 8 | Train_loss: 1.04715 | Val_loss: 3.41943 | Val_Accuracy: 0.72\n",
      "Epoch no: 9 | Train_loss: 0.98286 | Val_loss: 3.55145 | Val_Accuracy: 0.73\n",
      "Epoch no: 10 | Train_loss: 0.93345 | Val_loss: 3.7251 | Val_Accuracy: 0.74\n",
      "Best accuracy is : %73.73991935483872 for batch_size =64\n",
      "Epoch no: 1 | Train_loss: 1.86825 | Val_loss: 1.84786 | Val_Accuracy: 0.47\n",
      "Epoch no: 2 | Train_loss: 1.80974 | Val_loss: 2.38293 | Val_Accuracy: 0.55\n",
      "Epoch no: 3 | Train_loss: 1.44744 | Val_loss: 2.65068 | Val_Accuracy: 0.64\n",
      "Epoch no: 4 | Train_loss: 1.25003 | Val_loss: 2.91641 | Val_Accuracy: 0.66\n",
      "Epoch no: 5 | Train_loss: 1.09777 | Val_loss: 3.25839 | Val_Accuracy: 0.72\n",
      "Epoch no: 6 | Train_loss: 0.92357 | Val_loss: 3.5689 | Val_Accuracy: 0.75\n",
      "Epoch no: 7 | Train_loss: 0.8133 | Val_loss: 3.90279 | Val_Accuracy: 0.76\n",
      "Epoch no: 8 | Train_loss: 0.72713 | Val_loss: 4.09484 | Val_Accuracy: 0.78\n",
      "Epoch no: 9 | Train_loss: 0.66821 | Val_loss: 4.34595 | Val_Accuracy: 0.78\n",
      "Epoch no: 10 | Train_loss: 0.62392 | Val_loss: 4.43922 | Val_Accuracy: 0.79\n",
      "Best accuracy is : %78.64999999999999 for batch_size =16\n",
      "Epoch no: 1 | Train_loss: 1.77906 | Val_loss: 2.73391 | Val_Accuracy: 0.57\n",
      "Epoch no: 2 | Train_loss: 1.43192 | Val_loss: 3.1047 | Val_Accuracy: 0.63\n",
      "Epoch no: 3 | Train_loss: 1.28835 | Val_loss: 3.37617 | Val_Accuracy: 0.67\n",
      "Epoch no: 4 | Train_loss: 1.1173 | Val_loss: 3.84003 | Val_Accuracy: 0.72\n",
      "Epoch no: 5 | Train_loss: 0.95112 | Val_loss: 4.11202 | Val_Accuracy: 0.76\n",
      "Epoch no: 6 | Train_loss: 0.83488 | Val_loss: 4.46689 | Val_Accuracy: 0.77\n",
      "Epoch no: 7 | Train_loss: 0.75247 | Val_loss: 4.51316 | Val_Accuracy: 0.78\n",
      "Epoch no: 8 | Train_loss: 0.68031 | Val_loss: 5.10584 | Val_Accuracy: 0.77\n",
      "Epoch no: 9 | Train_loss: 0.62812 | Val_loss: 5.4009 | Val_Accuracy: 0.79\n",
      "Epoch no: 10 | Train_loss: 0.58642 | Val_loss: 5.5527 | Val_Accuracy: 0.8\n",
      "Best accuracy is : %79.75 for batch_size =8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{128: 0.6635416666666667, 64: 0.7373991935483871, 16: 0.7865, 8: 0.7975}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_dict = lstm_train_test_process(has_embedding=False)\n",
    "lstm_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doguc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\conv.py:298: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\Convolution.cpp:744.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no: 1 | Train_loss: 2.15433 | Val_loss: 1.90775 | Val_Accuracy: 0.47\n",
      "Epoch no: 2 | Train_loss: 1.76741 | Val_loss: 2.06209 | Val_Accuracy: 0.49\n",
      "Epoch no: 3 | Train_loss: 1.59209 | Val_loss: 2.28754 | Val_Accuracy: 0.57\n",
      "Epoch no: 4 | Train_loss: 1.48846 | Val_loss: 2.46273 | Val_Accuracy: 0.61\n",
      "Epoch no: 5 | Train_loss: 1.43235 | Val_loss: 2.58502 | Val_Accuracy: 0.62\n",
      "Epoch no: 6 | Train_loss: 1.39461 | Val_loss: 2.6686 | Val_Accuracy: 0.63\n",
      "Epoch no: 7 | Train_loss: 1.36629 | Val_loss: 2.72721 | Val_Accuracy: 0.65\n",
      "Epoch no: 8 | Train_loss: 1.34279 | Val_loss: 2.77863 | Val_Accuracy: 0.65\n",
      "Epoch no: 9 | Train_loss: 1.32294 | Val_loss: 2.82391 | Val_Accuracy: 0.65\n",
      "Epoch no: 10 | Train_loss: 1.30589 | Val_loss: 2.86511 | Val_Accuracy: 0.65\n",
      "Best accuracy is : %65.36458333333334 for batch_size =128\n",
      "Epoch no: 1 | Train_loss: 2.12655 | Val_loss: 2.0888 | Val_Accuracy: 0.49\n",
      "Epoch no: 2 | Train_loss: 1.7843 | Val_loss: 2.29548 | Val_Accuracy: 0.53\n",
      "Epoch no: 3 | Train_loss: 1.67731 | Val_loss: 2.47125 | Val_Accuracy: 0.55\n",
      "Epoch no: 4 | Train_loss: 1.59861 | Val_loss: 2.61639 | Val_Accuracy: 0.57\n",
      "Epoch no: 5 | Train_loss: 1.54915 | Val_loss: 2.74378 | Val_Accuracy: 0.58\n",
      "Epoch no: 6 | Train_loss: 1.51985 | Val_loss: 2.84423 | Val_Accuracy: 0.59\n",
      "Epoch no: 7 | Train_loss: 1.496 | Val_loss: 2.90921 | Val_Accuracy: 0.6\n",
      "Epoch no: 8 | Train_loss: 1.46631 | Val_loss: 2.97811 | Val_Accuracy: 0.6\n",
      "Epoch no: 9 | Train_loss: 1.44532 | Val_loss: 3.04204 | Val_Accuracy: 0.61\n",
      "Epoch no: 10 | Train_loss: 1.4284 | Val_loss: 3.09259 | Val_Accuracy: 0.61\n",
      "Best accuracy is : %61.23991935483871 for batch_size =64\n",
      "Epoch no: 1 | Train_loss: 1.85728 | Val_loss: 2.26289 | Val_Accuracy: 0.53\n",
      "Epoch no: 2 | Train_loss: 1.58444 | Val_loss: 2.48039 | Val_Accuracy: 0.59\n",
      "Epoch no: 3 | Train_loss: 1.49415 | Val_loss: 2.61203 | Val_Accuracy: 0.6\n",
      "Epoch no: 4 | Train_loss: 1.44989 | Val_loss: 2.68405 | Val_Accuracy: 0.61\n",
      "Epoch no: 5 | Train_loss: 1.42377 | Val_loss: 2.71349 | Val_Accuracy: 0.62\n",
      "Epoch no: 6 | Train_loss: 1.40764 | Val_loss: 2.74595 | Val_Accuracy: 0.62\n",
      "Epoch no: 7 | Train_loss: 1.39476 | Val_loss: 2.77287 | Val_Accuracy: 0.62\n",
      "Epoch no: 8 | Train_loss: 1.38487 | Val_loss: 2.78934 | Val_Accuracy: 0.62\n",
      "Epoch no: 9 | Train_loss: 1.37707 | Val_loss: 2.79853 | Val_Accuracy: 0.62\n",
      "Epoch no: 10 | Train_loss: 1.37052 | Val_loss: 2.80991 | Val_Accuracy: 0.63\n",
      "Best accuracy is : %62.55 for batch_size =16\n",
      "Epoch no: 1 | Train_loss: 1.7533 | Val_loss: 2.61057 | Val_Accuracy: 0.57\n",
      "Epoch no: 2 | Train_loss: 1.49988 | Val_loss: 3.107 | Val_Accuracy: 0.61\n",
      "Epoch no: 3 | Train_loss: 1.44427 | Val_loss: 3.29824 | Val_Accuracy: 0.62\n",
      "Epoch no: 4 | Train_loss: 1.41343 | Val_loss: 3.45941 | Val_Accuracy: 0.62\n",
      "Epoch no: 5 | Train_loss: 1.39567 | Val_loss: 3.56367 | Val_Accuracy: 0.62\n",
      "Epoch no: 6 | Train_loss: 1.38242 | Val_loss: 3.63315 | Val_Accuracy: 0.62\n",
      "Epoch no: 7 | Train_loss: 1.37095 | Val_loss: 3.68032 | Val_Accuracy: 0.63\n",
      "Epoch no: 8 | Train_loss: 1.36143 | Val_loss: 3.72773 | Val_Accuracy: 0.63\n",
      "Epoch no: 9 | Train_loss: 1.3538 | Val_loss: 3.75724 | Val_Accuracy: 0.63\n",
      "Epoch no: 10 | Train_loss: 1.34726 | Val_loss: 3.81755 | Val_Accuracy: 0.63\n",
      "Best accuracy is : %62.9 for batch_size =8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{128: 0.6536458333333334, 64: 0.6123991935483871, 16: 0.6255, 8: 0.629}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_dict_embed = cnn_train_test_process(has_embedding=True)\n",
    "cnn_dict_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no: 1 | Train_loss: 2.4812 | Val_loss: 1.92425 | Val_Accuracy: 0.47\n",
      "Epoch no: 2 | Train_loss: 1.87832 | Val_loss: 1.93447 | Val_Accuracy: 0.47\n",
      "Epoch no: 3 | Train_loss: 1.78449 | Val_loss: 2.00018 | Val_Accuracy: 0.47\n",
      "Epoch no: 4 | Train_loss: 1.69302 | Val_loss: 2.1008 | Val_Accuracy: 0.5\n",
      "Epoch no: 5 | Train_loss: 1.62001 | Val_loss: 2.19069 | Val_Accuracy: 0.56\n",
      "Epoch no: 6 | Train_loss: 1.55053 | Val_loss: 2.26896 | Val_Accuracy: 0.59\n",
      "Epoch no: 7 | Train_loss: 1.49251 | Val_loss: 2.35082 | Val_Accuracy: 0.6\n",
      "Epoch no: 8 | Train_loss: 1.45453 | Val_loss: 2.42348 | Val_Accuracy: 0.62\n",
      "Epoch no: 9 | Train_loss: 1.42683 | Val_loss: 2.48707 | Val_Accuracy: 0.62\n",
      "Epoch no: 10 | Train_loss: 1.40534 | Val_loss: 2.5432 | Val_Accuracy: 0.63\n",
      "Best accuracy is : %62.96874999999999 for batch_size =128\n",
      "Epoch no: 1 | Train_loss: 2.80057 | Val_loss: 2.79407 | Val_Accuracy: 0.18\n",
      "Epoch no: 2 | Train_loss: 2.7362 | Val_loss: 2.81659 | Val_Accuracy: 0.18\n",
      "Epoch no: 3 | Train_loss: 2.69811 | Val_loss: 2.84353 | Val_Accuracy: 0.18\n",
      "Epoch no: 4 | Train_loss: 2.67711 | Val_loss: 2.8571 | Val_Accuracy: 0.19\n",
      "Epoch no: 5 | Train_loss: 1.94444 | Val_loss: 2.13694 | Val_Accuracy: 0.56\n",
      "Epoch no: 6 | Train_loss: 1.71909 | Val_loss: 2.3267 | Val_Accuracy: 0.57\n",
      "Epoch no: 7 | Train_loss: 1.64465 | Val_loss: 2.44661 | Val_Accuracy: 0.57\n",
      "Epoch no: 8 | Train_loss: 1.60667 | Val_loss: 2.53662 | Val_Accuracy: 0.58\n",
      "Epoch no: 9 | Train_loss: 1.58203 | Val_loss: 2.61629 | Val_Accuracy: 0.58\n",
      "Epoch no: 10 | Train_loss: 1.56392 | Val_loss: 2.68122 | Val_Accuracy: 0.58\n",
      "Best accuracy is : %58.06451612903226 for batch_size =64\n",
      "Epoch no: 1 | Train_loss: 1.8025 | Val_loss: 2.23612 | Val_Accuracy: 0.56\n",
      "Epoch no: 2 | Train_loss: 1.52132 | Val_loss: 2.47946 | Val_Accuracy: 0.61\n",
      "Epoch no: 3 | Train_loss: 1.44358 | Val_loss: 2.60695 | Val_Accuracy: 0.64\n",
      "Epoch no: 4 | Train_loss: 1.3953 | Val_loss: 2.71391 | Val_Accuracy: 0.65\n",
      "Epoch no: 5 | Train_loss: 1.36236 | Val_loss: 2.79381 | Val_Accuracy: 0.65\n",
      "Epoch no: 6 | Train_loss: 1.33816 | Val_loss: 2.85838 | Val_Accuracy: 0.66\n",
      "Epoch no: 7 | Train_loss: 1.32035 | Val_loss: 2.91373 | Val_Accuracy: 0.66\n",
      "Epoch no: 8 | Train_loss: 1.30674 | Val_loss: 2.95885 | Val_Accuracy: 0.66\n",
      "Epoch no: 9 | Train_loss: 1.29588 | Val_loss: 2.98758 | Val_Accuracy: 0.66\n",
      "Epoch no: 10 | Train_loss: 1.28698 | Val_loss: 3.01409 | Val_Accuracy: 0.66\n",
      "Best accuracy is : %66.35 for batch_size =16\n",
      "Epoch no: 1 | Train_loss: 1.93865 | Val_loss: 2.6492 | Val_Accuracy: 0.48\n",
      "Epoch no: 2 | Train_loss: 1.7199 | Val_loss: 2.89843 | Val_Accuracy: 0.52\n",
      "Epoch no: 3 | Train_loss: 1.64838 | Val_loss: 3.0968 | Val_Accuracy: 0.53\n",
      "Epoch no: 4 | Train_loss: 1.59861 | Val_loss: 3.30357 | Val_Accuracy: 0.55\n",
      "Epoch no: 5 | Train_loss: 1.56632 | Val_loss: 3.42966 | Val_Accuracy: 0.56\n",
      "Epoch no: 6 | Train_loss: 1.54422 | Val_loss: 3.53592 | Val_Accuracy: 0.56\n",
      "Epoch no: 7 | Train_loss: 1.52673 | Val_loss: 3.61011 | Val_Accuracy: 0.57\n",
      "Epoch no: 8 | Train_loss: 1.51279 | Val_loss: 3.64902 | Val_Accuracy: 0.57\n",
      "Epoch no: 9 | Train_loss: 1.50045 | Val_loss: 3.68287 | Val_Accuracy: 0.57\n",
      "Epoch no: 10 | Train_loss: 1.4911 | Val_loss: 3.70605 | Val_Accuracy: 0.57\n",
      "Best accuracy is : %57.25 for batch_size =8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{128: 0.6296875, 64: 0.5806451612903226, 16: 0.6635, 8: 0.5725}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_dict = cnn_train_test_process(has_embedding=False)\n",
    "cnn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no: 1 | Train_loss: 1.89296 | Val_loss: 1.8519 | Val_Accuracy: 0.47\n",
      "Epoch no: 2 | Train_loss: 1.84997 | Val_loss: 1.85176 | Val_Accuracy: 0.47\n",
      "Epoch no: 3 | Train_loss: 1.84967 | Val_loss: 1.85132 | Val_Accuracy: 0.47\n",
      "Epoch no: 4 | Train_loss: 1.84935 | Val_loss: 1.8508 | Val_Accuracy: 0.47\n",
      "Epoch no: 5 | Train_loss: 1.84908 | Val_loss: 1.85033 | Val_Accuracy: 0.47\n",
      "Epoch no: 6 | Train_loss: 1.84887 | Val_loss: 1.84999 | Val_Accuracy: 0.47\n",
      "Epoch no: 7 | Train_loss: 1.84867 | Val_loss: 1.84966 | Val_Accuracy: 0.47\n",
      "Epoch no: 8 | Train_loss: 1.84849 | Val_loss: 1.84974 | Val_Accuracy: 0.47\n",
      "Epoch no: 9 | Train_loss: 1.84836 | Val_loss: 1.84928 | Val_Accuracy: 0.47\n",
      "Epoch no: 10 | Train_loss: 1.84823 | Val_loss: 1.84883 | Val_Accuracy: 0.47\n",
      "Best accuracy is : %46.875 for batch_size =128\n",
      "Epoch no: 1 | Train_loss: 1.87653 | Val_loss: 1.84923 | Val_Accuracy: 0.47\n",
      "Epoch no: 2 | Train_loss: 1.85253 | Val_loss: 1.84829 | Val_Accuracy: 0.47\n",
      "Epoch no: 3 | Train_loss: 1.85169 | Val_loss: 1.8469 | Val_Accuracy: 0.47\n",
      "Epoch no: 4 | Train_loss: 1.85103 | Val_loss: 1.84583 | Val_Accuracy: 0.47\n",
      "Epoch no: 5 | Train_loss: 1.85051 | Val_loss: 1.84526 | Val_Accuracy: 0.47\n",
      "Epoch no: 6 | Train_loss: 1.85009 | Val_loss: 1.84504 | Val_Accuracy: 0.47\n",
      "Epoch no: 7 | Train_loss: 1.84979 | Val_loss: 1.84498 | Val_Accuracy: 0.47\n",
      "Epoch no: 8 | Train_loss: 1.84947 | Val_loss: 1.84493 | Val_Accuracy: 0.47\n",
      "Epoch no: 9 | Train_loss: 1.85129 | Val_loss: 1.84564 | Val_Accuracy: 0.47\n",
      "Epoch no: 10 | Train_loss: 1.84929 | Val_loss: 1.84539 | Val_Accuracy: 0.47\n",
      "Best accuracy is : %47.02620967741936 for batch_size =64\n",
      "Epoch no: 1 | Train_loss: 1.86922 | Val_loss: 1.84808 | Val_Accuracy: 0.47\n",
      "Epoch no: 2 | Train_loss: 1.85907 | Val_loss: 1.86147 | Val_Accuracy: 0.47\n",
      "Epoch no: 3 | Train_loss: 1.86423 | Val_loss: 1.85034 | Val_Accuracy: 0.47\n",
      "Epoch no: 4 | Train_loss: 1.85246 | Val_loss: 1.88607 | Val_Accuracy: 0.47\n",
      "Epoch no: 5 | Train_loss: 1.71785 | Val_loss: 2.04748 | Val_Accuracy: 0.5\n",
      "Epoch no: 6 | Train_loss: 1.61229 | Val_loss: 2.20477 | Val_Accuracy: 0.52\n",
      "Epoch no: 7 | Train_loss: 1.53061 | Val_loss: 2.36422 | Val_Accuracy: 0.58\n",
      "Epoch no: 8 | Train_loss: 1.46713 | Val_loss: 2.51337 | Val_Accuracy: 0.58\n",
      "Epoch no: 9 | Train_loss: 1.38289 | Val_loss: 2.64278 | Val_Accuracy: 0.63\n",
      "Epoch no: 10 | Train_loss: 1.30874 | Val_loss: 2.68733 | Val_Accuracy: 0.65\n",
      "Best accuracy is : %64.7 for batch_size =16\n",
      "Epoch no: 1 | Train_loss: 1.87174 | Val_loss: 1.85267 | Val_Accuracy: 0.47\n",
      "Epoch no: 2 | Train_loss: 1.87867 | Val_loss: 1.86865 | Val_Accuracy: 0.47\n",
      "Epoch no: 3 | Train_loss: 1.83255 | Val_loss: 1.92325 | Val_Accuracy: 0.48\n",
      "Epoch no: 4 | Train_loss: 1.82297 | Val_loss: 1.87709 | Val_Accuracy: 0.47\n",
      "Epoch no: 5 | Train_loss: 1.87528 | Val_loss: 1.87671 | Val_Accuracy: 0.47\n",
      "Epoch no: 6 | Train_loss: 1.87397 | Val_loss: 1.87573 | Val_Accuracy: 0.47\n",
      "Epoch no: 7 | Train_loss: 1.87333 | Val_loss: 1.86993 | Val_Accuracy: 0.47\n",
      "Epoch no: 8 | Train_loss: 1.87295 | Val_loss: 1.86995 | Val_Accuracy: 0.47\n",
      "Epoch no: 9 | Train_loss: 1.87073 | Val_loss: 1.90129 | Val_Accuracy: 0.47\n",
      "Epoch no: 10 | Train_loss: 1.86921 | Val_loss: 1.87366 | Val_Accuracy: 0.47\n",
      "Best accuracy is : %48.199999999999996 for batch_size =8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{128: 0.46875, 64: 0.47026209677419356, 16: 0.647, 8: 0.482}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_dict_embed = rnn_train_test_process(has_embedding=True)\n",
    "rnn_dict_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no: 1 | Train_loss: 1.9038 | Val_loss: 1.85123 | Val_Accuracy: 0.47\n",
      "Epoch no: 2 | Train_loss: 1.84974 | Val_loss: 1.85099 | Val_Accuracy: 0.47\n",
      "Epoch no: 3 | Train_loss: 1.84952 | Val_loss: 1.85082 | Val_Accuracy: 0.47\n",
      "Epoch no: 4 | Train_loss: 1.84924 | Val_loss: 1.85063 | Val_Accuracy: 0.47\n",
      "Epoch no: 5 | Train_loss: 1.849 | Val_loss: 1.8505 | Val_Accuracy: 0.47\n",
      "Epoch no: 6 | Train_loss: 1.8488 | Val_loss: 1.85042 | Val_Accuracy: 0.47\n",
      "Epoch no: 7 | Train_loss: 1.84863 | Val_loss: 1.85032 | Val_Accuracy: 0.47\n",
      "Epoch no: 8 | Train_loss: 1.84847 | Val_loss: 1.85031 | Val_Accuracy: 0.47\n",
      "Epoch no: 9 | Train_loss: 1.84833 | Val_loss: 1.85022 | Val_Accuracy: 0.47\n",
      "Epoch no: 10 | Train_loss: 1.84823 | Val_loss: 1.84981 | Val_Accuracy: 0.47\n",
      "Best accuracy is : %46.875 for batch_size =128\n",
      "Epoch no: 1 | Train_loss: 1.88061 | Val_loss: 1.84803 | Val_Accuracy: 0.47\n",
      "Epoch no: 2 | Train_loss: 1.85284 | Val_loss: 1.84776 | Val_Accuracy: 0.47\n",
      "Epoch no: 3 | Train_loss: 1.85217 | Val_loss: 1.84736 | Val_Accuracy: 0.47\n",
      "Epoch no: 4 | Train_loss: 1.85165 | Val_loss: 1.84685 | Val_Accuracy: 0.47\n",
      "Epoch no: 5 | Train_loss: 1.85121 | Val_loss: 1.84645 | Val_Accuracy: 0.47\n",
      "Epoch no: 6 | Train_loss: 1.85084 | Val_loss: 1.84621 | Val_Accuracy: 0.47\n",
      "Epoch no: 7 | Train_loss: 1.85049 | Val_loss: 1.84577 | Val_Accuracy: 0.47\n",
      "Epoch no: 8 | Train_loss: 1.82361 | Val_loss: 1.88513 | Val_Accuracy: 0.47\n",
      "Epoch no: 9 | Train_loss: 1.80669 | Val_loss: 1.87657 | Val_Accuracy: 0.47\n",
      "Epoch no: 10 | Train_loss: 1.80903 | Val_loss: 1.88934 | Val_Accuracy: 0.47\n",
      "Best accuracy is : %47.02620967741936 for batch_size =64\n",
      "Epoch no: 1 | Train_loss: 1.8745 | Val_loss: 1.84933 | Val_Accuracy: 0.47\n",
      "Epoch no: 2 | Train_loss: 1.83402 | Val_loss: 1.98511 | Val_Accuracy: 0.48\n",
      "Epoch no: 3 | Train_loss: 1.74259 | Val_loss: 1.97933 | Val_Accuracy: 0.51\n",
      "Epoch no: 4 | Train_loss: 1.70721 | Val_loss: 1.86282 | Val_Accuracy: 0.47\n",
      "Epoch no: 5 | Train_loss: 1.71907 | Val_loss: 1.99773 | Val_Accuracy: 0.51\n",
      "Epoch no: 6 | Train_loss: 1.68356 | Val_loss: 2.09642 | Val_Accuracy: 0.52\n",
      "Epoch no: 7 | Train_loss: 1.64315 | Val_loss: 2.08653 | Val_Accuracy: 0.53\n",
      "Epoch no: 8 | Train_loss: 1.61356 | Val_loss: 2.27788 | Val_Accuracy: 0.53\n",
      "Epoch no: 9 | Train_loss: 1.58933 | Val_loss: 2.2071 | Val_Accuracy: 0.5\n",
      "Epoch no: 10 | Train_loss: 1.51897 | Val_loss: 2.28878 | Val_Accuracy: 0.57\n",
      "Best accuracy is : %57.15 for batch_size =16\n",
      "Epoch no: 1 | Train_loss: 1.87282 | Val_loss: 1.85109 | Val_Accuracy: 0.47\n",
      "Epoch no: 2 | Train_loss: 1.8664 | Val_loss: 2.39128 | Val_Accuracy: 0.46\n",
      "Epoch no: 3 | Train_loss: 1.81739 | Val_loss: 1.95557 | Val_Accuracy: 0.47\n",
      "Epoch no: 4 | Train_loss: 1.83165 | Val_loss: 1.92816 | Val_Accuracy: 0.47\n",
      "Epoch no: 5 | Train_loss: 1.82991 | Val_loss: 1.94648 | Val_Accuracy: 0.47\n",
      "Epoch no: 6 | Train_loss: 1.83287 | Val_loss: 1.9075 | Val_Accuracy: 0.47\n",
      "Epoch no: 7 | Train_loss: 1.8345 | Val_loss: 1.9065 | Val_Accuracy: 0.47\n",
      "Epoch no: 8 | Train_loss: 1.82754 | Val_loss: 2.07711 | Val_Accuracy: 0.47\n",
      "Epoch no: 9 | Train_loss: 1.82804 | Val_loss: 1.89141 | Val_Accuracy: 0.47\n",
      "Epoch no: 10 | Train_loss: 1.84087 | Val_loss: 1.96077 | Val_Accuracy: 0.47\n",
      "Best accuracy is : %47.349999999999994 for batch_size =8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{128: 0.46875, 64: 0.47026209677419356, 16: 0.5715, 8: 0.4735}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_dict = rnn_train_test_process(has_embedding=False)\n",
    "rnn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no: 1 | Train_loss: 1.87666 | Val_loss: 1.85373 | Val_Accuracy: 0.47\n",
      "Epoch no: 2 | Train_loss: 1.84497 | Val_loss: 1.82604 | Val_Accuracy: 0.47\n",
      "Epoch no: 3 | Train_loss: 1.72127 | Val_loss: 1.59909 | Val_Accuracy: 0.53\n",
      "Epoch no: 4 | Train_loss: 1.57468 | Val_loss: 1.54572 | Val_Accuracy: 0.54\n",
      "Epoch no: 5 | Train_loss: 1.523 | Val_loss: 1.50194 | Val_Accuracy: 0.56\n",
      "Epoch no: 6 | Train_loss: 1.47818 | Val_loss: 1.44208 | Val_Accuracy: 0.59\n",
      "Epoch no: 7 | Train_loss: 1.45263 | Val_loss: 1.44767 | Val_Accuracy: 0.59\n",
      "Epoch no: 8 | Train_loss: 1.40381 | Val_loss: 1.34322 | Val_Accuracy: 0.61\n",
      "Epoch no: 9 | Train_loss: 1.37887 | Val_loss: 1.33811 | Val_Accuracy: 0.61\n",
      "Epoch no: 10 | Train_loss: 1.33646 | Val_loss: 1.29381 | Val_Accuracy: 0.61\n",
      "Best accuracy is : %60.9375 for batch_size =128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{128: 0.609375}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_custom_dict_embed = custom_rnn_train_test_process(has_embedding=True)\n",
    "rnn_custom_dict_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch no: 1 | Train_loss: 1.91467 | Val_loss: 1.80823 | Val_Accuracy: 0.47\n",
      "Epoch no: 2 | Train_loss: 1.82411 | Val_loss: 1.83959 | Val_Accuracy: 0.47\n",
      "Epoch no: 3 | Train_loss: 1.75514 | Val_loss: 1.56368 | Val_Accuracy: 0.51\n",
      "Epoch no: 4 | Train_loss: 1.5274 | Val_loss: 1.4769 | Val_Accuracy: 0.55\n",
      "Epoch no: 5 | Train_loss: 1.48404 | Val_loss: 1.48919 | Val_Accuracy: 0.55\n",
      "Epoch no: 6 | Train_loss: 1.46543 | Val_loss: 1.47847 | Val_Accuracy: 0.54\n",
      "Epoch no: 7 | Train_loss: 1.44881 | Val_loss: 1.45877 | Val_Accuracy: 0.56\n",
      "Epoch no: 8 | Train_loss: 1.43498 | Val_loss: 1.43826 | Val_Accuracy: 0.56\n",
      "Epoch no: 9 | Train_loss: 1.42354 | Val_loss: 1.42047 | Val_Accuracy: 0.56\n",
      "Epoch no: 10 | Train_loss: 1.41049 | Val_loss: 1.39065 | Val_Accuracy: 0.55\n",
      "Best accuracy is : %55.93749999999999 for batch_size =128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{128: 0.559375}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_custom_dict = custom_rnn_train_test_process(has_embedding=False)\n",
    "rnn_custom_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_list_embed = [['lstm_embed' + str(i),(lstm_dict_embed[i])] for i in list(lstm_dict_embed.keys())]\n",
    "lstm_list = [['lstm_' + str(i),lstm_dict[i]] for i in list(lstm_dict.keys())]\n",
    "\n",
    "rnn_list_embed = [['rnn_embed' + str(i),rnn_dict_embed[i]] for i in list(rnn_dict_embed.keys())]\n",
    "rnn_list = [['rnn_' + str(i),rnn_dict[i]] for i in list(rnn_dict.keys())]\n",
    "\n",
    "rnn_custom_list_embed = [['rnn_custom_embed' + str(i),rnn_custom_dict_embed[i]] for i in list(rnn_custom_dict_embed.keys())]\n",
    "rnn_custom_list = [['rnn_custom_' + str(i),rnn_custom_dict[i]] for i in list(rnn_custom_dict.keys())]\n",
    "\n",
    "cnn_list_embed = [['cnn_embed' + str(i),cnn_dict_embed[i]] for i in list(cnn_dict_embed.keys())]\n",
    "cnn_list = [['cnn_' + str(i),cnn_dict[i]] for i in list(cnn_dict.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_list = lstm_list_embed + lstm_list + rnn_list_embed + rnn_list + rnn_custom_list_embed + rnn_custom_list + cnn_list_embed + cnn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['lstm_8', 0.7975],\n",
       " ['lstm_embed16', 0.793],\n",
       " ['lstm_16', 0.7865],\n",
       " ['lstm_embed64', 0.7832661290322581],\n",
       " ['lstm_embed8', 0.7755],\n",
       " ['lstm_embed128', 0.7463541666666667],\n",
       " ['lstm_64', 0.7373991935483871],\n",
       " ['lstm_128', 0.6635416666666667],\n",
       " ['cnn_16', 0.6635],\n",
       " ['cnn_embed128', 0.6536458333333334],\n",
       " ['rnn_embed16', 0.647],\n",
       " ['cnn_128', 0.6296875],\n",
       " ['cnn_embed8', 0.629],\n",
       " ['cnn_embed16', 0.6255],\n",
       " ['cnn_embed64', 0.6123991935483871],\n",
       " ['rnn_custom_embed128', 0.609375],\n",
       " ['cnn_64', 0.5806451612903226],\n",
       " ['cnn_8', 0.5725],\n",
       " ['rnn_16', 0.5715],\n",
       " ['rnn_custom_128', 0.559375],\n",
       " ['rnn_embed8', 0.482],\n",
       " ['rnn_8', 0.4735],\n",
       " ['rnn_embed64', 0.47026209677419356],\n",
       " ['rnn_64', 0.47026209677419356],\n",
       " ['rnn_embed128', 0.46875],\n",
       " ['rnn_128', 0.46875]]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_list.sort(key=lambda x:x[1])\n",
    "total_list = total_list[::-1]\n",
    "total_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_array = np.array(total_list)[:,1].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,7))\n",
    "plt.bar(np.array(total_list)[:,0],acc_array)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['lstm_embed128', 'lstm_embed64', 'lstm_embed16', 'lstm_embed8',\n",
       "       'lstm_128', 'lstm_64', 'lstm_16', 'lstm_8', 'rnn_embed128',\n",
       "       'rnn_embed64', 'rnn_embed16', 'rnn_embed8', 'rnn_128', 'rnn_64',\n",
       "       'rnn_16', 'rnn_8', 'rnn_custom_embed128', 'rnn_custom_128',\n",
       "       'cnn_embed128', 'cnn_embed64', 'cnn_embed16', 'cnn_embed8',\n",
       "       'cnn_128', 'cnn_64', 'cnn_16', 'cnn_8'], dtype='<U19')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(total_list)[:,0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ef7cd2e160683df5bc50936fdc15f17e8ae0d292a9877125d3322640160a1ab5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
